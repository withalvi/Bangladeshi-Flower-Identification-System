{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42899,"status":"ok","timestamp":1737693665805,"user":{"displayName":"Md. Zunayed Ahmed","userId":"17544397531006123542"},"user_tz":-360},"id":"YMhlqpPPoLAk","outputId":"fc6e64e0-aad8-4bda-f133-ce2f49d7ab31"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Essential imports\n","import os\n","import torch\n","import torchvision\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader, random_split\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n","import seaborn as sns\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3032,"status":"ok","timestamp":1737693699973,"user":{"displayName":"Md. Zunayed Ahmed","userId":"17544397531006123542"},"user_tz":-360},"id":"_ThgHVlGzkoD","outputId":"d0c41a5d-ec52-48fb-c019-5034e069b77b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5342,"status":"ok","timestamp":1737693706715,"user":{"displayName":"Md. Zunayed Ahmed","userId":"17544397531006123542"},"user_tz":-360},"id":"qgS9Pr5MougX","outputId":"59626c44-1028-4b4a-aa10-c526a7559042"},"outputs":[{"name":"stdout","output_type":"stream","text":["Detected 17 classes: [' গোলাপ-Rose', 'অপরাজিতা -Clitoria ternatea', 'কচুরি ফুল-water hyacinths', 'কদম - burflower tree', 'কাঠগোলাপ-Frangipani', 'কৃষ্ণচূড়া-Delonix regia', 'গাঁদা-Tagetes', 'চন্দ্রপ্রভা-Tecoma stans', 'জবা ফুল-Hibiscus Flower', 'ঢোল কলমি - Pink morning glory', 'নয়নতারা-Catharanthus roseus', 'পলাশ-Butea monosperma', 'বুনো ডেইজি-Trailing Daisy', 'রঙ্গন-Ixora coccinea Linn', 'লজ্জাবতী-Mimosa', 'শাপলা-Water lily', 'শিমুল ফুল- Bombax ceiba']\n","Dataset split: 2372 training, 677 validation, 340 test samples.\n"]}],"source":["# Dataset path\n","dataset_path = '/content/drive/MyDrive/dataset'\n","\n","# Data transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # Resize images to 224x224 (required for ResNet18)\n","    transforms.ToTensor(),         # Convert images to tensors\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize for ResNet\n","])\n","\n","# Load dataset\n","dataset = datasets.ImageFolder(dataset_path, transform=transform)\n","\n","# Automatically detect the number of classes\n","num_classes = len(dataset.classes)\n","print(f\"Detected {num_classes} classes: {dataset.classes}\")\n","\n","# Split the dataset\n","train_size = int(0.7 * len(dataset))\n","val_size = int(0.20 * len(dataset))\n","test_size = len(dataset) - train_size - val_size\n","\n","train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n","\n","# DataLoaders\n","batch_size = 64\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","print(f\"Dataset split: {train_size} training, {val_size} validation, {test_size} test samples.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1070,"status":"ok","timestamp":1737693710495,"user":{"displayName":"Md. Zunayed Ahmed","userId":"17544397531006123542"},"user_tz":-360},"id":"wYqhxqpOo7JI","outputId":"b7447a35-2c7d-4043-9a24-167220cb18dd"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 139MB/s]\n"]}],"source":["# Load the pre-trained ResNet18 model\n","model = models.resnet18(pretrained=True)\n","\n","# Modify the final layer to match the number of classes in your dataset\n","model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n","\n","# Define the device (use GPU if available)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","\n","# Define the loss function and optimizer\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training function\n","def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n","    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n","\n","    for epoch in range(epochs):\n","        print(f\"Epoch {epoch+1}/{epochs}\")\n","        model.train()\n","\n","        train_loss, train_correct = 0, 0\n","        for images, labels in train_loader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","            train_correct += (outputs.argmax(dim=1) == labels).sum().item()\n","\n","        train_loss /= len(train_loader)\n","        train_acc = train_correct / len(train_loader.dataset)\n","\n","        model.eval()\n","        val_loss, val_correct = 0, 0\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","                val_correct += (outputs.argmax(dim=1) == labels).sum().item()\n","\n","        val_loss /= len(val_loader)\n","        val_acc = val_correct / len(val_loader.dataset)\n","\n","        history['train_loss'].append(train_loss)\n","        history['val_loss'].append(val_loss)\n","        history['train_acc'].append(train_acc)\n","        history['val_acc'].append(val_acc)\n","\n","        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n","        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n","\n","    return history\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"b3Nn3yxkzZlX","outputId":"e40d4bc7-6d8d-4cd3-dfe5-2d827e7a2b8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","Train Loss: 0.5227, Train Acc: 0.8449\n","Val Loss: 1.1102, Val Acc: 0.7253\n","Epoch 2/50\n","Train Loss: 0.2106, Train Acc: 0.9431\n","Val Loss: 0.5241, Val Acc: 0.8759\n","Epoch 3/50\n","Train Loss: 0.1817, Train Acc: 0.9465\n","Val Loss: 1.0935, Val Acc: 0.7504\n","Epoch 4/50\n","Train Loss: 0.0963, Train Acc: 0.9726\n","Val Loss: 0.2327, Val Acc: 0.9232\n","Epoch 5/50\n","Train Loss: 0.1291, Train Acc: 0.9743\n","Val Loss: 0.5057, Val Acc: 0.8656\n","Epoch 6/50\n","Train Loss: 0.1753, Train Acc: 0.9570\n","Val Loss: 1.0222, Val Acc: 0.7947\n","Epoch 7/50\n","Train Loss: 0.2897, Train Acc: 0.9288\n","Val Loss: 0.4369, Val Acc: 0.8774\n","Epoch 8/50\n","Train Loss: 0.2500, Train Acc: 0.9465\n","Val Loss: 0.3495, Val Acc: 0.8996\n","Epoch 9/50\n","Train Loss: 0.1628, Train Acc: 0.9540\n","Val Loss: 0.3680, Val Acc: 0.8996\n","Epoch 10/50\n","Train Loss: 0.0601, Train Acc: 0.9865\n","Val Loss: 0.1954, Val Acc: 0.9513\n","Epoch 11/50\n","Train Loss: 0.0900, Train Acc: 0.9781\n","Val Loss: 0.3083, Val Acc: 0.9291\n","Epoch 12/50\n","Train Loss: 0.0546, Train Acc: 0.9848\n","Val Loss: 0.2287, Val Acc: 0.9380\n","Epoch 13/50\n","Train Loss: 0.0292, Train Acc: 0.9966\n","Val Loss: 0.1575, Val Acc: 0.9542\n","Epoch 14/50\n","Train Loss: 0.0595, Train Acc: 0.9848\n","Val Loss: 0.2283, Val Acc: 0.9542\n","Epoch 15/50\n","Train Loss: 0.0152, Train Acc: 0.9949\n","Val Loss: 0.2080, Val Acc: 0.9498\n","Epoch 16/50\n","Train Loss: 0.1626, Train Acc: 0.9962\n","Val Loss: 0.2422, Val Acc: 0.9513\n","Epoch 17/50\n","Train Loss: 0.1445, Train Acc: 0.9629\n","Val Loss: 0.7712, Val Acc: 0.8257\n","Epoch 18/50\n","Train Loss: 0.1189, Train Acc: 0.9722\n","Val Loss: 0.2921, Val Acc: 0.9114\n","Epoch 19/50\n","Train Loss: 0.0942, Train Acc: 0.9743\n","Val Loss: 0.3312, Val Acc: 0.9129\n","Epoch 20/50\n","Train Loss: 0.0306, Train Acc: 0.9907\n","Val Loss: 0.3184, Val Acc: 0.9158\n","Epoch 21/50\n"]}],"source":["# Train the model\n","epochs = 50\n","history = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"elapsed":372,"status":"error","timestamp":1737693575909,"user":{"displayName":"Md. Zunayed Ahmed","userId":"17544397531006123542"},"user_tz":-360},"id":"dyMcWLvn5tk7","outputId":"cb23243e-0a37-4247-d8aa-0dd3bbd91eb0"},"outputs":[{"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-2afd622f74f4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mplot_training_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]}],"source":["# Plot the accuracy and loss curves\n","def plot_training_history(history):\n","    epochs = range(1, len(history['train_loss']) + 1)\n","\n","    # Plot loss\n","    plt.figure(figsize=(12, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, history['train_loss'], label='Training Loss')\n","    plt.plot(epochs, history['val_loss'], label='Validation Loss')\n","    plt.title('Loss Curves')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    # Plot accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, history['train_acc'], label='Training Accuracy')\n","    plt.plot(epochs, history['val_acc'], label='Validation Accuracy')\n","    plt.title('Accuracy Curves')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Call the function\n","plot_training_history(history)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZvY9HOQ-F9w"},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sns\n","\n","# Evaluate the model on the test dataset\n","def evaluate_model(model, test_loader):\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, preds = torch.max(outputs, 1)\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(preds.cpu().numpy())\n","\n","    return y_true, y_pred\n","\n","# Get true and predicted labels\n","y_true, y_pred = evaluate_model(model, test_loader)\n","\n","# Classification report\n","print(\"Classification Report:\")\n","print(classification_report(y_true, y_pred, target_names=dataset.classes))\n","\n","# Confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=dataset.classes, yticklabels=dataset.classes)\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7m5YwhjHAML6"},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","from sklearn.preprocessing import label_binarize\n","import numpy as np\n","\n","# Binarize the true labels for multi-class ROC\n","y_true_binarized = label_binarize(y_true, classes=list(range(num_classes)))\n","\n","# Get model predictions as probabilities\n","y_scores = []\n","model.eval()\n","with torch.no_grad():\n","    for images, _ in test_loader:\n","        images = images.to(device)\n","        outputs = model(images)\n","        y_scores.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n","\n","y_scores = np.array(y_scores)\n","\n","# Plot the ROC curves for each class\n","plt.figure(figsize=(10, 8))\n","for i in range(num_classes):\n","    fpr, tpr, _ = roc_curve(y_true_binarized[:, i], y_scores[:, i])\n","    roc_auc = auc(fpr, tpr)\n","    plt.plot(fpr, tpr, label=f'Class {dataset.classes[i]} (AUC = {roc_auc:.2f})')\n","\n","plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve')\n","plt.legend(loc='lower right')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZUS_ZLhBC0B"},"outputs":[],"source":["from PIL import Image\n","import random\n","\n","# Function to predict the class of an input image\n","def predict_and_visualize(model, image_path):\n","    # Load and preprocess the image\n","    image = Image.open(image_path).convert('RGB')\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","    input_tensor = transform(image).unsqueeze(0).to(device)\n","\n","    # Predict the class\n","    model.eval()\n","    with torch.no_grad():\n","        outputs = model(input_tensor)\n","        _, predicted_class = torch.max(outputs, 1)\n","\n","    predicted_label = dataset.classes[predicted_class.item()]\n","    print(f\"Predicted Class: {predicted_label}\")\n","\n","    # Visualize the input image\n","    plt.figure(figsize=(10, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(image)\n","    plt.axis('off')\n","    plt.title(f\"Input Image (Predicted: {predicted_label})\")\n","\n","    # Visualize a matching image from the dataset\n","    matching_indices = [i for i, label in enumerate(dataset.targets) if label == predicted_class.item()]\n","    if matching_indices:\n","        random_match = random.choice(matching_indices)\n","        matching_image, _ = dataset[random_match]\n","        plt.subplot(1, 2, 2)\n","        plt.imshow(matching_image.permute(1, 2, 0).numpy())\n","        plt.axis('off')\n","        plt.title(f\"Matching Image ({predicted_label})\")\n","    else:\n","        print(\"No matching image found in the dataset.\")\n","\n","    plt.show()\n","\n","# Provide the path to an input image\n","image_path = '/content/drive/MyDrive/dataset/অপরাজিতা -Clitoria ternatea/blue-klitorie-454729_640.jpg'  # Replace with your test image path\n","predict_and_visualize(model, image_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBM35IcJD7NC"},"outputs":[],"source":["# Define the path to save the model\n","model_save_path = '/content/drive/MyDrive/dataset'\n","\n","# Save the model's state dictionary (recommended)\n","torch.save(model.state_dict(), model_save_path)\n","print(f\"Model saved to {model_save_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W55tOo1GE6Am"},"outputs":[],"source":["def calculate_accuracy(model, loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = correct / total * 100\n","    return accuracy\n","\n","# Calculate accuracy on the test dataset\n","test_accuracy = calculate_accuracy(model, test_loader)\n","print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}